{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c1ceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef2812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOCATION = 'export/fire_model'  # will be created\n",
    "\n",
    "IMG_HEIGHT = 448  # same value as used while model training\n",
    "IMG_WIDTH = IMG_HEIGHT\n",
    "IMG_CHANNELS = 3\n",
    "CLASS_NAMES = 'Fire No-Fire'.split()\n",
    "\n",
    "CHECK_POINT_DIR='gs://fire_detection_anurag/models/accuracy/chkpts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6fa87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(CHECK_POINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38bc1ed",
   "metadata": {},
   "source": [
    "Set signature of serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64518390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_step1(filename):\n",
    "    img_bytes = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img_bytes,\n",
    "                               channels=IMG_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,],\n",
    "                                            dtype=tf.string)])\n",
    "def preprocess_step2(filenames):\n",
    "    input_images = tf.map_fn(\n",
    "                             preprocess_step1,\n",
    "                             filenames,\n",
    "                             fn_output_signature=tf.float32\n",
    "                            )\n",
    "    \n",
    "    return {\n",
    "            'input_images': input_images\n",
    "           }\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,\n",
    "                                             IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS],\n",
    "                                            dtype=tf.float32)])\n",
    "def get_model_pred(input_images):\n",
    "    batch_pred = model(input_images) # same as model.predict()\n",
    "    top_prob = tf.math.reduce_max(batch_pred,\n",
    "                                  axis=[1])\n",
    "    pred_label_index = tf.math.argmax(batch_pred,\n",
    "                                      axis=1)\n",
    "    pred_label = tf.gather(tf.convert_to_tensor(CLASS_NAMES),\n",
    "                           pred_label_index)\n",
    "    \n",
    "    return {\n",
    "            'probability': top_prob,\n",
    "            'image_type_int': pred_label_index,\n",
    "            'image_type_str': pred_label\n",
    "           }\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,],\n",
    "                                            dtype=tf.string)])\n",
    "def predict_filename(filenames):\n",
    "    preproc_output = preprocess_step2(filenames)\n",
    "    \n",
    "    return get_model_pred(**preproc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81c7a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/fire_model/assets\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('export',\n",
    "              ignore_errors=True)\n",
    "\n",
    "os.mkdir('export')\n",
    "\n",
    "model.save(MODEL_LOCATION,\n",
    "           signatures={\n",
    "                       'serving_default': predict_filename,\n",
    "                      }\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa59d6b",
   "metadata": {},
   "source": [
    "Check model signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1574f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['filenames'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: serving_default_filenames:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['image_type_int'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "    outputs['image_type_str'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:1\n",
      "    outputs['probability'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:2\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 448, 448, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {MODEL_LOCATION} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d475848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/Computer_Vision/fire_detection/Inferencing/pub_sub\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9656a",
   "metadata": {},
   "source": [
    "## Deploy model to Vertex-AI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4eca9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://export/fire_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_model/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "/ [4/4 files][ 10.9 MiB/ 10.9 MiB] 100% Done                                    \n",
      "Operation completed over 4 objects/10.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r export/* gs://fire_detection_anurag/models/pub_sub_beam/export/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c5e91",
   "metadata": {},
   "source": [
    "**Note**: While choosing appropriate 'MODEL_NAME', make sure there is no already deployed model (on Vertex-AI) having the exact same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "099230e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vertex_deploy.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vertex_deploy.sh\n",
    "REGION=\"us-central1\"\n",
    "ENDPOINT_NAME=\"fire_endpoint\"\n",
    "MODEL_NAME=\"fire_detector_pubsub\"\n",
    "MODEL_LOCATION=\"gs://fire_detection_anurag/models/pub_sub_beam/export/fire_model\"\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
    "\n",
    "for i in \"$@\"\n",
    "do\n",
    "case $i in\n",
    "        -r=*|--region=*) REGION=\"${i#*=}\"; shift ;;\n",
    "        -e=*|--endpoint_name=*) ENDPOINT_NAME=\"${i#*=}\"; shift ;;\n",
    "        -m=*|--model_name=*) MODEL_NAME=\"${i#*=}\"; shift ;;\n",
    "        -l=*|--model_location=*) MODEL_LOCATION=\"${i#*=}\"; shift ;;\n",
    "        -i=*|--image_uri=*) IMAGE_URI=\"${i#*=}\"; shift ;;\n",
    "        *) echo \"Unknown parameter passed: $1\"; exit 1 ;;\n",
    "esac\n",
    "done\n",
    "\n",
    "echo \"Deploying model $MODEL_NAME\"\n",
    "\n",
    "if [[ $(gcloud ai endpoints list --region=$REGION --format=\"value(display_name)\" | grep $ENDPOINT_NAME) ]]; then\n",
    "    echo \"The endpoint named $ENDPOINT_NAME already exists.\"\n",
    "else\n",
    "    # Create endpoint.\n",
    "    echo \"Creating $ENDPOINT_NAME endpoint now.\"\n",
    "    gcloud ai endpoints create \\\n",
    "      --region=$REGION \\\n",
    "      --display-name=$ENDPOINT_NAME\n",
    "fi\n",
    "\n",
    "ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$ENDPOINT_NAME\")\n",
    "echo \"The endpoint_id is $ENDPOINT_ID\"\n",
    "\n",
    "if [[ $(gcloud ai models list --region=$REGION --format=\"value(display_name)\" | grep $MODEL_NAME) ]]; then\n",
    "    echo \"The model named $MODEL_NAME already exists.\"\n",
    "else\n",
    "    # Upload model.\n",
    "    echo \"Uploading $MODEL_NAME model now.\"\n",
    "    gcloud ai models upload \\\n",
    "      --region=$REGION \\\n",
    "      --display-name=$MODEL_NAME \\\n",
    "      --container-image-uri=$IMAGE_URI \\\n",
    "      --artifact-uri=$MODEL_LOCATION\n",
    "fi\n",
    "\n",
    "MODEL_ID=$(gcloud ai models list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$MODEL_NAME\")\n",
    "echo \"The model_id is $MODEL_ID\"\n",
    "\n",
    "echo \"Deploying model now\"\n",
    "gcloud ai endpoints deploy-model $ENDPOINT_ID\\\n",
    "  --region=$REGION \\\n",
    "  --model=$MODEL_ID \\\n",
    "  --display-name=$MODEL_NAME \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b98c501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model fire_detector_pubsub\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The endpoint named fire_endpoint already exists.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The endpoint_id is 6569494015031377920\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Uploading fire_detector_pubsub model now.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7204935938303066112]...done.                            \n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The model_id is projects/9118975290/locations/us-central1/models/13304090696089600\n",
      "Deploying model now\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7398590722279997440]...done.                            \n",
      "Deployed a model to the endpoint 6569494015031377920. Id of the deployed model: 668687787641274368.\n"
     ]
    }
   ],
   "source": [
    "!bash vertex_deploy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c04cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
