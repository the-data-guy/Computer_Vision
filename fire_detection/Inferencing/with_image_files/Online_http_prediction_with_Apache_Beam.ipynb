{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d74f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8499439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPredict:\n",
    "    def __init__(self, project, region, endpoint_id):\n",
    "        self._api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
    "                                                                                                                   region,\n",
    "                                                                                                                   project,\n",
    "                                                                                                                   region,\n",
    "                                                                                                                   endpoint_id\n",
    "                                                                                                                  )   \n",
    "        \n",
    "    def __call__(self, filenames):        \n",
    "        token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "        if isinstance(filenames, str):\n",
    "            # Only one element, put it into a batch of 1.\n",
    "            data = {\n",
    "                    \"instances\": [\n",
    "                                  {\"filenames\": filenames}\n",
    "                                 ]\n",
    "                   }\n",
    "        else:\n",
    "            data = {\n",
    "                    \"instances\": []\n",
    "                   }\n",
    "            for f in filenames:\n",
    "                data[\"instances\"].append({\n",
    "                                          \"filenames\" : f\n",
    "                                        })\n",
    "        # print(data)\n",
    "        headers = {\"Authorization\": \"Bearer \" + token }\n",
    "        response = requests.post(self._api,\n",
    "                                 json=data,\n",
    "                                 headers=headers)\n",
    "        response = json.loads(response.content.decode(\"utf-8\"))\n",
    "        \n",
    "        if isinstance(filenames, str):\n",
    "            result = response[\"predictions\"][0]\n",
    "            result[\"filename\"] = filenames\n",
    "            yield result\n",
    "        else:\n",
    "            for (a,b) in zip(filenames, response[\"predictions\"]):\n",
    "                result = b\n",
    "                result[\"filename\"] = a\n",
    "                yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc6833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"kubeflow-1-0-2\"\n",
    "REGION = \"us-central1\"\n",
    "ENDPOINT_ID = \"2613644692339818496\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d413659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://fire_detection_anurag/test_images/batchinputs.jsonl',\n",
       " 'gs://fire_detection_anurag/test_images/fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire5.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire5.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/prediction-fire20211105140403-2021-11-05T15:04:29.256648Z',\n",
       " 'gs://fire_detection_anurag/test_images/test.jsonl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = tf.io.gfile.glob(\"gs://fire_detection_anurag/test_images/*\")\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bf5404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://fire_detection_anurag/test_images/fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire5.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire5.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb841d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_type_str': 'Fire', 'image_type_int': 0, 'probability': 0.994521737, 'filename': 'gs://fire_detection_anurag/test_images/fire1.jpg'}\n",
      "{'image_type_int': 0, 'image_type_str': 'Fire', 'probability': 0.711659372, 'filename': 'gs://fire_detection_anurag/test_images/fire2.jpg'}\n",
      "{'probability': 0.987360537, 'image_type_int': 0, 'image_type_str': 'Fire', 'filename': 'gs://fire_detection_anurag/test_images/fire3.jpg'}\n",
      "{'probability': 0.983968496, 'image_type_int': 0, 'image_type_str': 'Fire', 'filename': 'gs://fire_detection_anurag/test_images/fire4.jpg'}\n",
      "{'probability': 0.995875299, 'image_type_str': 'Fire', 'image_type_int': 0, 'filename': 'gs://fire_detection_anurag/test_images/fire5.jpg'}\n",
      "{'probability': 0.827532887, 'image_type_str': 'No-Fire', 'image_type_int': 1, 'filename': 'gs://fire_detection_anurag/test_images/no_fire1.jpg'}\n",
      "{'image_type_str': 'No-Fire', 'probability': 0.990039051, 'image_type_int': 1, 'filename': 'gs://fire_detection_anurag/test_images/no_fire2.jpg'}\n",
      "{'probability': 0.984749556, 'image_type_int': 1, 'image_type_str': 'No-Fire', 'filename': 'gs://fire_detection_anurag/test_images/no_fire3.jpg'}\n",
      "{'image_type_int': 1, 'probability': 0.981689095, 'image_type_str': 'No-Fire', 'filename': 'gs://fire_detection_anurag/test_images/no_fire4.jpg'}\n",
      "{'probability': 0.993100286, 'image_type_int': 1, 'image_type_str': 'No-Fire', 'filename': 'gs://fire_detection_anurag/test_images/no_fire5.jpg'}\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as p:    \n",
    "    (p \n",
    "     | \"getinput\" >> beam.Create(filenames[1:-2]) \n",
    "     | \"batch\" >> beam.BatchElements(min_batch_size=2,\n",
    "                                     max_batch_size=3)\n",
    "     | \"getpred\" >> beam.FlatMap(ModelPredict(PROJECT,\n",
    "                                              REGION,\n",
    "                                              ENDPOINT_ID))\n",
    "     | \"write\" >> beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242976e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
