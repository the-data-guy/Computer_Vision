{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42469fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import base64\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cfd3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fire_detection\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random/center_crop (RandomCr (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_lr_flip (RandomFlip)  (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_brightness/n (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_embedding (KerasLa (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_hidden_1 (Dense)       (None, 32)                40992     \n",
      "_________________________________________________________________\n",
      "dense_hidden_2 (Dense)       (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "fire_detector (Dense)        (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 2,299,538\n",
      "Trainable params: 41,554\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_DIR='gs://fire_detection_anurag/models/accuracy/chkpts'\n",
    "\n",
    "model = tf.keras.models.load_model(CHECK_POINT_DIR)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd1dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOCATION = 'export/fire_bytes_model'  # will be created\n",
    "\n",
    "IMG_HEIGHT = 448  # same value as used while model training\n",
    "IMG_WIDTH = IMG_HEIGHT\n",
    "IMG_CHANNELS = 3\n",
    "CLASS_NAMES = 'Fire No-Fire'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61c855",
   "metadata": {},
   "source": [
    "Check manually first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec93c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_jpegfile(filename):\n",
    "    img_bytes = tf.io.read_file(filename)\n",
    "    return img_bytes\n",
    "    \n",
    "def preprocess(img_bytes):\n",
    "    img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f2e78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://fire_detection_anurag/test_images/fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire5.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire5.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = tf.io.gfile.glob(\"gs://fire_detection_anurag/test_images/*\")\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6ac0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9867954  0.01320453]]\n",
      "[[0.71165985 0.28834015]]\n",
      "[[0.99001807 0.0099819 ]]\n",
      "[[0.9839685  0.01603149]]\n",
      "[[0.9958753  0.00412475]]\n",
      "[[0.17246704 0.82753295]]\n",
      "[[0.0099609  0.99003905]]\n",
      "[[0.01525044 0.98474956]]\n",
      "[[0.01463307 0.98536694]]\n",
      "[[0.00689968 0.9931003 ]]\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    img_bytes = read_from_jpegfile(filename)\n",
    "    img = preprocess(img_bytes)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    pred = model.predict(img)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a08b5",
   "metadata": {},
   "source": [
    "## Set model signature which can predict on image bytes coming directly i.e. without image being first loaded to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc31ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model signature-1 (to be used as default)\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,],\n",
    "                                            dtype=tf.string)])\n",
    "def predict_bytes(img_bytes):\n",
    "    input_images = tf.map_fn(\n",
    "                             preprocess,\n",
    "                             img_bytes,\n",
    "                             fn_output_signature=tf.float32\n",
    "                            )\n",
    "    batch_pred = model(input_images) # same as model.predict()\n",
    "    top_prob = tf.math.reduce_max(batch_pred,\n",
    "                                  axis=[1])\n",
    "    pred_label_index = tf.math.argmax(batch_pred,\n",
    "                                      axis=1)\n",
    "    pred_label = tf.gather(tf.convert_to_tensor(CLASS_NAMES),\n",
    "                           pred_label_index)\n",
    "    \n",
    "    return {\n",
    "            'probability': top_prob,\n",
    "            'image_type_int': pred_label_index,\n",
    "            'image_type_str': pred_label\n",
    "           }\n",
    "\n",
    "\n",
    "# set model signature-2\n",
    "# If image file is provided, we first need to convert it to bytes\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,],\n",
    "                                            dtype=tf.string)])\n",
    "def predict_filename(filenames):\n",
    "    img_bytes = tf.map_fn(\n",
    "                          tf.io.read_file,  # extract bytes\n",
    "                          filenames\n",
    "                         )\n",
    "    result = predict_bytes(img_bytes)  # get prediction\n",
    "    result['filename'] = filenames  # map with corresponding input image\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5d4aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/fire_bytes_model/assets\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('export',\n",
    "              ignore_errors=True)\n",
    "os.mkdir('export')\n",
    "\n",
    "model.save(MODEL_LOCATION,\n",
    "           signatures={\n",
    "                       'serving_default': predict_bytes,\n",
    "                       'from_images': predict_filename\n",
    "                      }\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c809d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"from_images\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir $MODEL_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c9a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['img_bytes'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_img_bytes:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['image_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "  outputs['image_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:1\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:2\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir $MODEL_LOCATION --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdafda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: from_images_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['filename'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['image_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['image_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:2\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:3\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir $MODEL_LOCATION --signature_def from_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6d326",
   "metadata": {},
   "source": [
    "Check locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ab1c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://fire_detection_anurag/test_images/fire1.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a0cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://fire_detection_anurag/test_images/fire1.jpg...\n",
      "/ [1 files][ 26.5 KiB/ 26.5 KiB]                                                \n",
      "Operation completed over 1 objects/26.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://fire_detection_anurag/test_images/fire1.jpg /tmp/fire1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3c7e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_type_int': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>, 'image_type_str': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Fire'], dtype=object)>, 'probability': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.99452174], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "with open('/tmp/fire1.jpg', 'rb') as ifp:\n",
    "    img_bytes = ifp.read()\n",
    "    serving_fn = tf.keras.models.load_model(MODEL_LOCATION).signatures['serving_default']\n",
    "    pred = serving_fn(tf.convert_to_tensor([img_bytes]))\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75d36e",
   "metadata": {},
   "source": [
    "## Deploy model to Vertex-AI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09ae5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://export/fire_bytes_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_bytes_model/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_bytes_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://export/fire_bytes_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "/ [4/4 files][ 10.9 MiB/ 10.9 MiB] 100% Done                                    \n",
      "Operation completed over 4 objects/10.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r export/* gs://fire_detection_anurag/models/bytes_inferencing/export/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a515ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vertex_ai_bytes_model_deploy.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile vertex_ai_bytes_model_deploy.sh\n",
    "REGION=\"us-central1\"\n",
    "ENDPOINT_NAME=\"fire_bytes_endpoint\"\n",
    "MODEL_NAME=\"fire_detector_bytes\"\n",
    "MODEL_LOCATION=\"gs://fire_detection_anurag/models/bytes_inferencing/export/fire_bytes_model\"\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
    "\n",
    "for i in \"$@\"\n",
    "do\n",
    "case $i in\n",
    "        -r=*|--region=*) REGION=\"${i#*=}\"; shift ;;\n",
    "        -e=*|--endpoint_name=*) ENDPOINT_NAME=\"${i#*=}\"; shift ;;\n",
    "        -m=*|--model_name=*) MODEL_NAME=\"${i#*=}\"; shift ;;\n",
    "        -l=*|--model_location=*) MODEL_LOCATION=\"${i#*=}\"; shift ;;\n",
    "        -i=*|--image_uri=*) IMAGE_URI=\"${i#*=}\"; shift ;;\n",
    "        *) echo \"Unknown parameter passed: $1\"; exit 1 ;;\n",
    "esac\n",
    "done\n",
    "\n",
    "echo \"Deploying model $MODEL_NAME\"\n",
    "\n",
    "if [[ $(gcloud ai endpoints list --region=$REGION --format=\"value(display_name)\" | grep $ENDPOINT_NAME) ]]; then\n",
    "    echo \"The endpoint named $ENDPOINT_NAME already exists.\"\n",
    "else\n",
    "    # Create endpoint.\n",
    "    echo \"Creating $ENDPOINT_NAME endpoint now.\"\n",
    "    gcloud ai endpoints create \\\n",
    "      --region=$REGION \\\n",
    "      --display-name=$ENDPOINT_NAME\n",
    "fi\n",
    "\n",
    "ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$ENDPOINT_NAME\")\n",
    "echo \"The endpoint_id is $ENDPOINT_ID\"\n",
    "\n",
    "if [[ $(gcloud ai models list --region=$REGION --format=\"value(display_name)\" | grep $MODEL_NAME) ]]; then\n",
    "    echo \"The model named $MODEL_NAME already exists.\"\n",
    "else\n",
    "    # Upload model.\n",
    "    echo \"Uploading $MODEL_NAME model now.\"\n",
    "    gcloud ai models upload \\\n",
    "      --region=$REGION \\\n",
    "      --display-name=$MODEL_NAME \\\n",
    "      --container-image-uri=$IMAGE_URI \\\n",
    "      --artifact-uri=$MODEL_LOCATION\n",
    "fi\n",
    "\n",
    "MODEL_ID=$(gcloud ai models list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$MODEL_NAME\")\n",
    "echo \"The model_id is $MODEL_ID\"\n",
    "\n",
    "echo \"Deploying model now\"\n",
    "gcloud ai endpoints deploy-model $ENDPOINT_ID\\\n",
    "  --region=$REGION \\\n",
    "  --model=$MODEL_ID \\\n",
    "  --display-name=$MODEL_NAME \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5170739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model fire_detector_bytes\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Creating fire_bytes_endpoint endpoint now.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [8453295052200869888]...done.                            \n",
      "Created AI Platform endpoint: projects/9118975290/locations/us-central1/endpoints/4876703505093492736.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The endpoint_id is 4876703505093492736\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Uploading fire_detector_bytes model now.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [1504240827168194560]...done.                            \n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The model_id is projects/9118975290/locations/us-central1/models/1620526207713935360\n",
      "Deploying model now\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [6440186018766258176]...done.                            \n",
      "Deployed a model to the endpoint 4876703505093492736. Id of the deployed model: 924830016447971328.\n"
     ]
    }
   ],
   "source": [
    "!bash vertex_ai_bytes_model_deploy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c476f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"kubeflow-1-0-2\"\n",
    "REGION = \"us-central1\"\n",
    "ENDPOINT_ID = \"4876703505093492736\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acddc124",
   "metadata": {},
   "source": [
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b1dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b64encode(filename):\n",
    "    with open(filename, 'rb') as ifp:\n",
    "        img_bytes = ifp.read()\n",
    "        return base64.b64encode(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb34a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "\n",
    "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
    "                                                                                                     REGION,\n",
    "                                                                                                     PROJECT,\n",
    "                                                                                                     REGION,\n",
    "                                                                                                     ENDPOINT_ID\n",
    "                                                                                                    )\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer \" + token }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa85abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://us-central1-aiplatform.googleapis.com/v1/projects/kubeflow-1-0-2/locations/us-central1/endpoints/4876703505093492736:predict'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6fd6bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://fire_detection_anurag/test_images/fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/fire5.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire1.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire2.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire3.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire4.jpg',\n",
       " 'gs://fire_detection_anurag/test_images/no_fire5.jpg']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0d71b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://fire_detection_anurag/test_images/fire1.jpg...\n",
      "/ [1 files][ 26.5 KiB/ 26.5 KiB]                                                \n",
      "Operation completed over 1 objects/26.5 KiB.                                     \n",
      "Copying gs://fire_detection_anurag/test_images/fire2.jpg...\n",
      "/ [1 files][ 83.0 KiB/ 83.0 KiB]                                                \n",
      "Operation completed over 1 objects/83.0 KiB.                                     \n",
      "Copying gs://fire_detection_anurag/test_images/no_fire1.jpg...\n",
      "/ [1 files][  7.0 KiB/  7.0 KiB]                                                \n",
      "Operation completed over 1 objects/7.0 KiB.                                      \n",
      "Copying gs://fire_detection_anurag/test_images/no_fire2.jpg...\n",
      "/ [1 files][  2.6 MiB/  2.6 MiB]                                                \n",
      "Operation completed over 1 objects/2.6 MiB.                                      \n",
      "Copying gs://fire_detection_anurag/test_images/no_fire3.jpg...\n",
      "/ [1 files][  1.4 MiB/  1.4 MiB]                                                \n",
      "Operation completed over 1 objects/1.4 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp gs://fire_detection_anurag/test_images/fire1.jpg /tmp/fire1.jpg\n",
    "gsutil cp gs://fire_detection_anurag/test_images/fire2.jpg /tmp/fire2.jpg\n",
    "gsutil cp gs://fire_detection_anurag/test_images/no_fire1.jpg /tmp/no_fire1.jpg\n",
    "gsutil cp gs://fire_detection_anurag/test_images/no_fire2.jpg /tmp/no_fire2.jpg\n",
    "gsutil cp gs://fire_detection_anurag/test_images/no_fire3.jpg /tmp/no_fire3.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce00d7",
   "metadata": {},
   "source": [
    "**Note**: Since jpg files might contain special characters, it's better to encode (base64) the file content, before sending the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c610711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"instances\": [\n",
    "                      {\n",
    "                       \"img_bytes\": {\"b64\": b64encode('/tmp/fire1.jpg')}\n",
    "                      },\n",
    "                      {\n",
    "                       \"img_bytes\": {\"b64\": b64encode('/tmp/no_fire1.jpg')}\n",
    "                      },\n",
    "                     ]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b0f8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(api,\n",
    "                         json=data,\n",
    "                         headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70cb5a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"predictions\": [\\n    {\\n      \"image_type_int\": 0,\\n      \"probability\": 0.994521737,\\n      \"image_type_str\": \"Fire\"\\n    },\\n    {\\n      \"probability\": 0.827533,\\n      \"image_type_int\": 1,\\n      \"image_type_str\": \"No-Fire\"\\n    }\\n  ],\\n  \"deployedModelId\": \"924830016447971328\",\\n  \"model\": \"projects/9118975290/locations/us-central1/models/1620526207713935360\",\\n  \"modelDisplayName\": \"fire_detector_bytes\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63178d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'image_type_int': 0,\n",
       "   'probability': 0.994521737,\n",
       "   'image_type_str': 'Fire'},\n",
       "  {'probability': 0.827533, 'image_type_int': 1, 'image_type_str': 'No-Fire'}],\n",
       " 'deployedModelId': '924830016447971328',\n",
       " 'model': 'projects/9118975290/locations/us-central1/models/1620526207713935360',\n",
       " 'modelDisplayName': 'fire_detector_bytes'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.content.decode('utf-8').replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7997529",
   "metadata": {},
   "source": [
    "**Note**: If we encounter a limit on the size of bytes sent at a time (due to large no. of prediction requests), that can hinder inferencing at scale. In that case, we can try parallelizing the inferencing process e.g. using Apache Beam, like we did in one of the notebooks for inferencing from image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92dceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
